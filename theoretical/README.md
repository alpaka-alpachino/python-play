### General decisions
Для решения последующих задач будет использоваться PyPy.
Это важно так как мы можем избежать стратегии с созданием многих процессов (с дополнительным интерпретатором на каждый) как это было бы в случае реализации параллелизма с CPython.
Вместо этого мы сможем использовать функционал Stackless интерпретатора. 

## 1 
### Нанести на картинку 1980х1280 водяной знак(размер 500x100). Предположительная загрузка сервера 1000 картинок/сек.
Для эффективного решения данной задачи важно учитывать 2 момента:
 - Нагрузка при работе с сетью (I/O bound), на это влияет вес картинки 1980х1280 плюс ожидаемое количество зарпосов в секунду.
   Для создания работы с запросами можно воспользоваться фреймворком,- сравниваем Flask, Django и Pyramid. 
   Для целей задачи выбор не критичен, поэтому или выбираем то в чем есть експертиза, или Flask так как он быстр и минималистичен (так же как и наш функционал).
   В случае если после запуска прототипа будет низкая пропускная способность - предлагается использовать и сконфигурировать nginx.
 - Обработка картинки (compute bound)
   Тут нужно использовать доступное количество ядер процессора чтоб использовать больше одного потока ОС и одновременно обрабатывать большее количество картинок.
   Предпологаю, что для 1000 картинок/секунду будет достаточно вертикального масштабирования (т.е. увеличить количество ядер процессора на сервере), чтоб удовлетворить нефункциональное требование.
   Взаимодействие с потоками ОС будет посредством микропотоков PyPy (`stackless`) - можно просто обернуть функцию обработки картинки в микропоток. 
   Для обработки картинок можно воспользоваться одной из [доступных библиотек](https://towardsdatascience.com/python-watermarking-old-vs-new-clunky-vs-clean-which-will-you-choose-5f4f1e75a9f3) при выборе стоит руководствоваться сложостью водных знаков и скоростью библиотеки.

## 2 
### Есть легаси код(много), написан однопоточно. В основном работа с сетью. Надо ускорить. Как будешь действовать?
Тип задачи, создающей основную нагрузку - I/O bound, это значит что вполне подходит конкурентное выполнение.
Чтоб максимально быстро добится результата с минимальными ресурсами по порядку идем по следующим пунктам пока скорость не будет удовлетворительной:
- Актуализировать версию пайтона, насколько возможно (в зависимости от того устаревшие ли зависимости или они поддерживают более актуальные версии пайтона, и насколько необходимо изменить сам синтаксис програмы).
- Проверить используемую имплементацию пайтона и по возможности перейти на самую быструю из совместимых с версией пайтона (и импортируемых пакетов) кодовой базой.
- Поставить nginx, поднять дополнительные серверы и распределить запросы на копии сервиса
- Пропрофилировать приложение и оценить ботлнеки - если не требует изменения дизайна приложения - ускорить.
- Переписать сериализированое выполнение на конкурентное, используя библиотеку `asyncio`.

## 3 
### Делаем скрапер. Пользователь грузит свое фото (лицо) на сайт и передает тип бороды, которое нужно наложить поверх фото. Бороду нужно скачать с другого сайта, т.к. они постоянно обновляются. 
### Как только получили новую бороду, наносим ее на картинку и отправляем обратно. На сервере 8 ядер. Как реализовать максимальный перформанс по количеству запросов?
Для обработки вебзапросов выбираем один из фреймворков - к примеру Django и настраиваем https, проверку ориджинов и т.п. (хоть мы и не созраняем фото а держим его только во время обработки, мы не хотим чтоб его украли во время передачи)
Дальше задача по сути напоминает задачу с водными знаками - у нас есть compute bound задача при наложении бороды на фото, для чего нужно будет задействовать большее количество ядер процессора, и у нас есть задача I/O bound когда мы скачиваем бороду.
Таким образом скачивание бороды стоит обернуть в корутину (`asyncio`), а функции наложения бороды в микропоток.

## 4 
### Скрапер. Хотим понять как меняются ставки на сайте бетинговой конторы. Пусть будет favbet. Одномоментно происходит 100 разных игр. Нам нужны изменения всех ставок для всех событий. Как реализовать такой скрапер?
Нам важно постоянно следить за состоянием каждой из 100 ставок предлагаю отдельно запустить в микропотоке (`stackless`), который будет каждую секунду стягивать с вебсайта интересующий нас обьект со списком состояний игр и сразу передавать его в канал.
Для вычитывания и обработки событий будет отдельный микропоток, ответственный за обработку обьекта сайта (ожидаю, что одного будет достаточно, но если на практике нет - создаем пул микропотоков).
Даная функция (обернутая в микропопток) будет вычитывать из обьекта сайта интересующую нас информацию и представлять ее структурой пайтон. Самая последняя (включающая изменения) копия обьекта даной структуры кешируется.
Допустим полученый новый обьект отличается от кешированого - обновляем кеш, отправляем в канал изменения.
Из канала с изменениями будет вычитывать отдельный микропоток, ответственный за сохранение изменений в хранилище (база даных должна подбираться с учетом того как долго должна хранится иформация и что с ней собираются делать в последствии).
Скрапер подбираем исходя из защиты вебсайта от сркапинга (нужно ли имитировать действия пользователя) и скорости. Начнем со Scrapy.

## 5  
### Пользователи совершают транзакции в системе. Система отправляет нотификации о статусе транзакций в очередь с минимальной задержкой. 
### Нужно выбрать сообщения из очереди и c минимальной задержкой  отправить в Viber и записать в БД лог нотификации. В среднем приходит 100 транзакций в секунду. Как это эффективно реализовать?
Решение данной задачи реализовуем используя конкурентное и паралельное выполнение (`asyncio`, `stackless`).
Для того чтобы добиться лучшей производительности можно сделать перформенс-тестирование задавая разное количество микропроцессов.
Флоу нотификации выглядит следующим образом:
Вычитав сообщение функция, обернутая в микропроцесс отправляет сообщение в вайбер и ожидает пока отправка закончится. После завершения отправки сообщения в вайбер все сообщения записываются в канал.
Отдельный пулл микропроцессов вычитывают сообщения из канала. Так как обычно лог нотификации в БД допустимо записать с большей задержкой, микропроцессы кешируют входящие логи и записывает пачками в базу данных.

## 6 
### Какой инструментарий(применительно к питону) будешь использовать для оценки своих решений?
Для оценки решений будет использован инструмент профилирования `vmprof` так как он указан как рекомендуемый имплементацией, что мы используем - [PyPy)](https://www.pypy.org/performance.html#profiling-vmprof).